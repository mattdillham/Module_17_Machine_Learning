# Module_17_Machine_Learning
# Analysis
# The precision scores for each model were as follows:
Oversampling-high_risk:0.01 low_risk: 1.00 avg/total: 0.99
SMOTE-high_risk:0.01 low_risk: 1.00 avg/total: 0.99 
Undersampling-high_risk:0.01 low_risk: 1.00 avg/total: 0.99 
Combination-high_risk:0.01 low_risk: 1.00 avg/total: 0.99 
Random Forest-high_risk:0.04 low_risk: 1.00 avg/total: 0.99 
Easy Ensemble-high_risk:0.07 low_risk: 1.00 avg/total: 0.99

# The recall scores for each model were as follows:
Oversampling-high_risk:0.66 low_risk: 0.67 avg/total: 0.67
SMOTE-high_risk:0.66 low_risk: 0.67 avg/total: 0.67 
Undersampling-high_risk:0.63 low_risk: 0.40 avg/total: 0.40 
Combination-high_risk:0.70 low_risk: 0.57 avg/total: 0.57 
Random Forest-high_risk:0.67 low_risk: 0.91 avg/total: 0.91 
Easy Ensemble-high_risk:0.91 low_risk: 0.94 avg/total: 0.94

# The accuracy scores for each model were as follows: 
Oversampling- 66%
SMOTE-63%
Undersampling-51%
Combination-63%
Random Forest-78%
Easy Ensemble-92%

# Recommendation and Justification
Out of all the models tested I would recommend the Easy Ensemble model. My justification is that it had the highest scores across the board. with a 99% precision average, a 94% recall average and a 92% accuracy score(14% higher than the second place spot held by Random Forest). If Easy Ensemble was out of the equation, Oversampling would be the recomendation, for it had the highest accuracy score and comparable averages. 

